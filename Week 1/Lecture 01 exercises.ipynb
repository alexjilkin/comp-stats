{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Mathematics and Statistics  \n",
    "MAST32001 Computational Statistics, Autumn 2023  \n",
    "Luigi Acerbi  \n",
    "Based on notebook by Antti Honkela\n",
    "\n",
    "# Lecture 1: Floating point numbers and numerics of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating point number basics\n",
    "\n",
    "Real numbers are typically represented as floating point numbers in computers. Floating point numbers use a fixed storage size and hence can offer only finite precision. Floating point numbers do not fulfill the usual axioms of real numbers, which means they can sometimes behave in unexpected ways.\n",
    "\n",
    "Background reading on floating point numbers:\n",
    "\n",
    "http://floating-point-gui.de/formats/fp/  \n",
    "http://floating-point-gui.de/errors/rounding/  \n",
    "http://floating-point-gui.de/errors/comparison/  \n",
    "http://floating-point-gui.de/errors/propagation/  \n",
    "https://hal.archives-ouvertes.fr/hal-00128124v5/document  \n",
    "and references therein.\n",
    "\n",
    "## Useful links\n",
    "\n",
    "https://courses.helsinki.fi/fi/aycsm90004en/135221588 : \"Data Analysis with Python\" MOOC  \n",
    "http://www.learnpython.org/ : Nice interactive Python tutorial  \n",
    "https://docs.python.org/3/tutorial/index.html : Official documentation for Python3  \n",
    "https://docs.scipy.org/doc/numpy/user/quickstart.html : Tutorial for one of the most important Python modules, SciPy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Computing with floating point numbers\n",
    "\n",
    "Write a program to increment `x = 0.0` by `0.1` 100 times. Compute `x - 10`. How do you interpret the result?\n",
    "\n",
    "Check other examples with different increments. In which cases can you get an exact result? Can you come up with a class of instances where the result is exact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9539925233402755e-14"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can write your Python code here\n",
    "x = 0.0\n",
    "\n",
    "for _ in range(100):\n",
    "    x += 0.1\n",
    "    \n",
    "x - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing log-probabilities\n",
    "\n",
    "Probabilities can sometimes be difficult to compute with floating point numbers as they can be very small non-negative numbers. These problems can often be avoided by using logarithms and storing $ \\log(p) $ instead of $ p $.\n",
    "\n",
    "Compute numerically the following probabilities and report them in the format $x \\cdot 10^y$:\n",
    "1. The probability of randomly drawing the 8191-letter HIV-1 genome from the 4-letter DNA alphabet.\n",
    "2. The probability that you need exactly 5000 throws of a regular 6-sided die to get the first 6. (*Hint*: [Geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution).)\n",
    "3. The probability that $ x = 200 $ when $ x \\sim \\mathrm{Poisson}(1)$.\n",
    "\n",
    "*Hints*: \n",
    "- The Python package Numpy contains basic numerical functions you will need. Just use `np.log()` for `log()` etc. You can use the properties of logarithms to convert natural logarithms to base 10 to make them more human-readable.\n",
    "- As commonly done, in point 3 above we denoted with $x \\sim P(\\theta)$ that $x$ is an instance of a random variable drawn from the probability density (or probability mass function) $P$ with parameters $\\theta$. In example 3, $P$ is a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) with rate parameter $\\lambda = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4931.47338896734\n",
      "-4931.47338896734\n",
      "-396.60520024246\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Define a function to print the values in the requested format.\n",
    "# For all y, we have\n",
    "#   p = 10^log10p = 10^(log10p - y) * 10^y\n",
    "# where the logarithm is in base 10.\n",
    "# By choosing y to be largest integer not greater than log10p, we have 1 <= x < 10.\n",
    "# def pretty_print_log10(log10p):\n",
    "\n",
    "#1\n",
    "logp1 = np.sum([np.log10(1/4) for _ in range(8191)])\n",
    "print(logp1)\n",
    "print(np.log10(1/4) * 8191)\n",
    "#2\n",
    "logp2 = np.sum([np.log10(5/6) for _ in range(4999)]) + np.log10(1/6)\n",
    "print(logp2)\n",
    "\n",
    "#3\n",
    "print(1 - poisson.cdf(100, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Log-sum-exp trick when working with log-probabilities\n",
    "\n",
    "Assuming one is working with log-probabilities as suggested above, one often runs into the need to normalise a set of log-probabilities $\\textbf{x} = (x_1, \\ldots, x_N)$. To do this, it is necessary to compute\n",
    "$$ z = \\log\\left( \\sum_{i=1}^N \\exp(x_i) \\right). $$\n",
    "This can be difficult as $ \\exp() $ can very easily overflow or underflow. These problems can be avoided by using the log-sum-exp (or logsumexp) trick discussed e.g. at\n",
    "https://lips.cs.princeton.edu/computing-log-sum-exp/\n",
    "\n",
    "1. Try to compute $ z $ directly for $\\textbf{x} = [-1000, -999, -1000]$.\n",
    "2. Compute $z$ again using the log-sum-exp trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-998.448555286068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/38vlh0g54yq0mx_cl1lqgzhc0000gn/T/ipykernel_21685/36776717.py:5: RuntimeWarning: divide by zero encountered in log10\n",
      "  z = np.log10(np.sum(np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#1\n",
    "x = np.array([-1000, -999, -1000])\n",
    "\n",
    "z = np.log10(np.sum(np.exp(x)))\n",
    "print(z)\n",
    "#2\n",
    "# log-sum-exp trick: subtract max(x) before taking exp() and add it back afterwards\n",
    "# Suggestion: write a logsumexp function first\n",
    "max = np.max(x)\n",
    "norm_x = x - max\n",
    "sum = np.log(np.sum(np.exp(norm_x))) + max\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Useful special functions\n",
    "\n",
    "Probability distributions often involve special functions such as the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) $\\Gamma(z)$. The gamma function is also useful as $ n! = \\Gamma(n+1) $, where $n!$ is $n$ factorial. Note that almost all numerical packages will offer a function that directly computes the *logarithm* of the Gamma function (often called something like `gammaln`).\n",
    "\n",
    "1. Check the manual of the Python package `scipy.special` to find the different forms of gamma function it offers.\n",
    "2. Redo task 3 of Exercise 2 using a suitable gamma function call from `scipy.special`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Numerical algorithms\n",
    "\n",
    "As an example of a numerical computation, let us consider the estimation of the variance of $ n $ numbers $ x_1, \\dots, x_n $.\n",
    "\n",
    "Denoting the mean of the numbers by $ \\bar{x}, $ the unbiased estimate of the sample variance is\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 =\n",
    "  \\frac{1}{n-1} \\sum_{i=1}^n (x_i^2 - 2 x_i \\bar{x} + \\bar{x}^2) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - 2 n \\bar{x}^2 + n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right).\n",
    "$$\n",
    "\n",
    "The variance can be estimated in a numerically stable manner using the first form, but this requires two passes through the data: first to compute the mean and then the second time to compute the sum of squared differences. The last form can be evaluated in single pass, but computing the difference of two potentially large positive numbers is numerically unstable.\n",
    "\n",
    "1. Write a function for computing the variance of a given array of numbers using the two-pass approach:\n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i $$\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 $$\n",
    "2. Write a function for computing the variance of a given array of numbers using the one-pass approach:\n",
    "$$ s^2 = \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right). $$\n",
    "3. Test your functions by generating 1000 random number from the distribution $ N(10^9, 1) $. (*Hint*: `numpy.random.randn()`)\n",
    "4. Implement Welford's accurate one-pass algorithm and test it with your data. (See e.g. http://jonisalonen.com/2013/deriving-welfords-method-for-computing-variance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "#1\n",
    "\n",
    "#2\n",
    "\n",
    "#3\n",
    "\n",
    "#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus extra: Early history of digital computers\n",
    "\n",
    "Statistics and computers have a long common history, and the first electronic computer Colossus was built by the British to perform statistical computations for breaking a German cryptosystem during World War II. This relatively unknown part of history is reported in detail in\n",
    "http://www.rutherfordjournal.org/article030109.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
